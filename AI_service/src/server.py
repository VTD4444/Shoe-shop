import sys
import os
import traceback
import joblib
from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))


sys.path.append(CURRENT_DIR)


try:
    from model_core import ShoeToxicModel
except ImportError as e:
    print("Lá»–I NGHIÃŠM TRá»ŒNG: Python khÃ´ng tÃ¬m tháº¥y file model_core.py")
    print(f" Python Ä‘ang tÃ¬m á»Ÿ: {sys.path}")
    raise e


BASE_DIR = os.path.dirname(CURRENT_DIR)

MODEL_PATH = os.path.join(BASE_DIR, "models", "shoe_toxic_v3.pkl")

print(f"ðŸ“‚ Server khá»Ÿi Ä‘á»™ng...")
print(f"ðŸ‘‰ Code Ä‘ang cháº¡y táº¡i: {CURRENT_DIR}")
print(f"ðŸ‘‰ Äang tÃ¬m model táº¡i: {MODEL_PATH}")


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

model = None

if os.path.exists(MODEL_PATH):
    print(f"âœ… TÃ¬m tháº¥y file model. Äang load...")
    try:
        model = joblib.load(MODEL_PATH)
        print(" MODEL LOAD THÃ€NH CÃ”NG!")
    except Exception as e:
        print(" LOAD MODEL FAILED (File lá»—i hoáº·c code model_core bá»‹ thay Ä‘á»•i)")
        print(" Error:", repr(e))
        traceback.print_exc()
else:
    print(f"âš ï¸ KHÃ”NG TÃŒM THáº¤Y FILE MODEL Táº I: {MODEL_PATH}")
    models_dir = os.path.dirname(MODEL_PATH)
    if os.path.exists(models_dir):
        print(f"ðŸ‘€ Trong thÆ° má»¥c models cÃ³: {os.listdir(models_dir)}")



class CommentReq(BaseModel):
    text: str


@app.get("/")
def home():
    return {
        "status": "Toxic Shoe API is running",
        "model_loaded": model is not None,
        "current_dir": CURRENT_DIR
    }

@app.post("/predict")
def predict(req: CommentReq):
    if model is None:
        return {
            "text": req.text,
            "is_toxic": False,
            "score": 0.0,
            "message": "âš ï¸ Lá»—i Server: Model chÆ°a Ä‘Æ°á»£c load (HÃ£y cháº¡y train trÆ°á»›c).",
            "error": "Model not found"
        }

    try:
        label, score = model.predict(req.text)
        is_toxic = (label == 1)

        msg = "BÃ¬nh luáº­n há»£p lá»‡."
        if is_toxic:
            if score >= 10:
                msg = "NgÃ´n tá»« thÃ´ tá»¥c/cáº¥m ká»µ!"
            else:
                msg = "Ná»™i dung tiÃªu cá»±c."

        return {
            "text": req.text,
            "is_toxic": is_toxic,
            "score": float(score),
            "message": msg
        }
    except Exception as e:
        traceback.print_exc()
        return {"error": str(e)}